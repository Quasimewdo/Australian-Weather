rm(list=ls())
data <- read.csv("weatherAUS.csv")
data
library(tidyr) #Gérer les dataframes
library(dplyr) #Gérer les dataframes
library(lubridate) #Gérer les dates
library(FactoMineR)
library(MASS)
library(pROC)
library(klaR)
library(rpart)
library(rpart.plot)
library(randomForest)
library(ISLR)
library(DMwR)
library(biotools)
rm(list=ls())
data <- read.csv("weatherAUS.csv")
head(data)
data = data[, -c(6, 7, 8, 9, 10, 11, 12, 13, 18, 19)]
head(data)
data = data %>% drop_na()
data <- mutate(data, Date = as.Date(Date))
data = data %>% mutate(Year = year(Date))
data = data[, -1]
head(data)
by_loca <- data %>% group_by(Location, Year)
head(by_loca)
by_year = by_loca %>% filter(Year >= 2010 & Year <= 2017)
data_year<- by_year %>% group_by(Location)
data_year = data_year %>% filter(n() > 2300)
data_year <- data_year %>% slice(1:2300)
dataReady = data_year[(19*2300+1):(20*2300),]
dataReady = dataReady[, -c(1, 13)]
head(dataReady)
dataReady$RainToday=as.factor(dataReady$RainToday)
dataReady$RainTomorrow=as.factor(dataReady$RainTomorrow)
attach(dataReady)
set.seed(1)
n <- nrow(dataReady)
p <- ncol(dataReady)-1
test.ratio <- .2 # ratio of test/train samples
n.test <- round(n*test.ratio)
n.test
tr <- sample(1:n,n.test)
data.test <- dataReady[tr,]
data.train <- dataReady[-tr,]
## Modèle
res_lda <- lda(RainTomorrow~.,data=data.train)
res_qda <- qda(RainTomorrow~.,data=data.train)
predict_lda = predict(res_lda, data.test)$class
predict_qda = predict(res_qda, data.test)$class
table_lda = table(data.test$RainTomorrow, predict_lda)
table_lda
table_qda = table(data.test$RainTomorrow, predict_qda)
table_qda
accuracy_lda = (table_lda[1,1]+table_lda[2,2])/length(predict_lda)  #mean(predict_lda == data.test$DIFF)
accuracy_lda
accuracy_qda = (table_qda[1,1]+table_qda[2,2])/length(predict_qda) #mean(predict_qda == data.test$DIFF)
accuracy_qda
#proba a posteriori de succes (dans la deuxième colonne) :
pred_lda <- predict(res_lda,newdata=data.test)$posterior[,2]
pred_qda <- predict(res_qda,newdata=data.test)$posterior[,2]
ROC_lda <- roc(data.test$RainTomorrow, pred_lda)
plot(ROC_lda, print.auc=TRUE,  print.auc.y = 0.5) # Afficher l'aire sous la courbe ROC sur le graphique
ROC_lda$auc # l'aire sous la courbe ROC
ROC_qda <- roc(data.test$RainTomorrow, pred_qda)
plot(ROC_qda, add=TRUE, col=2, print.auc=TRUE, print.auc.y=0.4)
ROC_qda$auc
dataBox = dataReady %>% mutate(RainToday = as.numeric(RainToday == "Yes"),
RainTomorrow = as.numeric(RainTomorrow == "Yes"))
boxM(data = dataBox, grouping = dataReady$RainTomorrow)
arbre=rpart(RainTomorrow~.,data.train)
#arbre le plus profond
arbre=rpart(RainTomorrow~.,data.train,control=rpart.control(minsplit=5,cp=0))
rpart.plot(arbre, type=4)
#xerror en fonction le nombre de noeuds
set.seed(1)
printcp(arbre)
plotcp(arbre)
cp.opt <- arbre$cptable[which.min(arbre$cptable[, "xerror"]), "CP"]
arbre.opt <- prune(arbre,cp=cp.opt)
print(arbre.opt)
rpart.plot(arbre.opt)
pred_cart = predict(arbre.opt, newdata = data.test, type="class")
table(data.test$RainTomorrow, pred_cart)
accuracy_cart = mean(pred_cart == data.test$RainTomorrow)
accuracy_cart
#proba a posteriori de succes (dans la deuxième colonne) :
pred_cart_prob <- predict(arbre.opt,newdata=data.test, type='prob')[,2]
ROC_cart <- roc(data.test$RainTomorrow, pred_cart_prob)
plot(ROC_cart, print.auc=TRUE,  print.auc.y = 0.5) # Afficher l'aire sous la courbe ROC sur le graphique
ROC_cart$auc # l'aire sous la courbe ROC
fit_RF <-  randomForest(RainTomorrow~., data.train)
fit_RF
plot(fit_RF)
table(data.test$RainTomorrow)
pred_rf = predict(fit_RF, newdata = data.test, type="class")
confusion = table(data.test$RainTomorrow, pred_rf)
confusion
accuracy_RF = mean(pred_rf == data.test$RainTomorrow)
accuracy_RF
err_RF = mean(pred_rf != data.test$RainTomorrow)
err_RF
# erreur class No :
confusion[1,2]/sum(confusion[1,])
# erreur class No :
confusion[2,1]/sum(confusion[2,])
#proba a posteriori de succes (dans la deuxième colonne) :
pred_rf_prob <- predict(fit_RF,newdata=data.test, type='prob')[,2]
ROC_rf <- roc(data.test$RainTomorrow, pred_rf_prob)
plot(ROC_rf, print.auc=TRUE,  print.auc.y = 0.5) # Afficher l'aire sous la courbe ROC sur le graphique
ROC_rf$auc # l'aire sous la courbe ROC
### Modèle
logit.train <- glm(RainTomorrow ~ ., family = binomial , data=data.train)
logit.train.AIC <- step(logit.train) #backward par defaut
pred_logit <- predict(logit.train.AIC, data.test, type="response")
class_logit <- ifelse(pred_logit >1/2, "Yes", "No")
table(data.test$RainTomorrow, class_logit)
accuracy_logit = mean(class_logit == data.test$RainTomorrow)
accuracy_logit
err = mean(class_logit != data.test$RainTomorrow) # taux erreur total
paste('err=',err)
err_No = confusion['No','Yes']/sum(confusion['No',]) # taux erreur classe No
paste('err_No=',err_No)
err_Yes = confusion['Yes', 'No']/sum(confusion['Yes',]) # taux erreur classe Yes
paste('err_Yes=',err_Yes)
data.train.balanced <- SMOTE(RainTomorrow ~., as.data.frame(data.train))
table(data.train.balanced$RainTomorrow)
fit_RF <- randomForest(RainTomorrow~.,data.train.balanced)
fit_RF
plot(fit_RF)
#Prédiction
class_RF= predict(fit_RF, newdata=data.test, type="response")
#Table de confusion
confusion=table(class_RF, data.test$RainTomorrow)
confusion
table(data.test$RainTomorrow)
#Accuracy
accuracy_RF = mean(class_RF == data.test$RainTomorrow)
accuracy_RF
# erreur class No :
err_No = confusion['Yes', 'No']/sum(confusion[,'No']) # taux erreur classe No
paste('err_No=',err_No)
# erreur class Yes :
err_Yes = confusion['No','Yes']/sum(confusion[,'Yes']) # taux erreur classe Yes
paste('err_Yes=',err_Yes)
logit.train <- glm(RainTomorrow ~ ., family = binomial , data=data.train.balanced)
logit.train.AIC <- step(logit.train) #backward par defaut
#Prédiction
pred_logit <- predict(logit.train.AIC, data.test, type="response")
class_logit <- ifelse(pred_logit >1/2, "Yes", "No")
#Confusion
confusion = table(class_logit, data.test$RainTomorrow)
accuracy_logit = mean(class_logit == data.test$RainTomorrow)
accuracy_logit
mean(class_logit != data.test$RainTomorrow) # taux erreur total
paste('err=',err)
err_No = confusion['Yes', 'No']/sum(confusion[,'No']) # taux erreur classe No
paste('err_No=',err_No)
err_Yes = confusion['No','Yes']/sum(confusion[,'Yes']) # taux erreur classe Yes
paste('err_Yes=',err_Yes)
